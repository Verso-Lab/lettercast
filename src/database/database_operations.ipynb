{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database Operations\n",
    "\n",
    "This notebook provides interactive access to the Neon database using our CRUD operations.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "from datetime import datetime, timezone\n",
    "from src.database import (\n",
    "    get_db,\n",
    "    get_podcast_by_id,\n",
    "    get_podcast_by_rss_url,\n",
    "    create_podcast,\n",
    "    list_podcasts,\n",
    "    get_episode_by_guid,\n",
    "    create_episode,\n",
    "    get_podcast_episodes,\n",
    "    get_recent_episodes\n",
    ")\n",
    "\n",
    "# Allow nested event loops in Jupyter\n",
    "nest_asyncio.apply()\n",
    "\n",
    "async def run_db_operation(operation):\n",
    "    \"\"\"Run a database operation in an async context\"\"\"\n",
    "    async with get_db() as db:\n",
    "        return await operation(db)\n",
    "\n",
    "def run_async(coro):\n",
    "    \"\"\"Run an async operation from a sync context\"\"\"\n",
    "    try:\n",
    "        loop = asyncio.get_running_loop()\n",
    "    except RuntimeError:\n",
    "        loop = asyncio.new_event_loop()\n",
    "        asyncio.set_event_loop(loop)\n",
    "    return loop.run_until_complete(coro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Function for Async Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_db_operation(operation):\n",
    "    \"\"\"Run a database operation in an async context\"\"\"\n",
    "    async with get_db() as db:\n",
    "        return await operation(db)\n",
    "\n",
    "def run_async(coro):\n",
    "    \"\"\"Run an async operation from a sync context\"\"\"\n",
    "    return asyncio.get_event_loop().run_until_complete(coro)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podcast Operations\n",
    "\n",
    "### List All Podcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all podcasts with episode counts\n",
    "podcasts = run_async(run_db_operation(lambda db: list_podcasts(db, with_episode_count=True)))\n",
    "\n",
    "for p in podcasts:\n",
    "    print(f\"\\nPodcast: {p['name']}\")\n",
    "    print(f\"ID: {p['id']}\")\n",
    "    print(f\"Episodes: {p.get('episode_count', 0)}\")\n",
    "    print(f\"RSS: {p['rss_url']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Podcast by RSS URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your RSS URL\n",
    "RSS_URL = \"https://techtalkweekly.com/feed\"\n",
    "\n",
    "podcast = run_async(run_db_operation(lambda db: get_podcast_by_rss_url(db, RSS_URL)))\n",
    "if podcast:\n",
    "    print(f\"Found: {podcast.name} (ID: {podcast.id})\")\n",
    "else:\n",
    "    print(\"Podcast not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_podcast_data = {\n",
    "    \"name\": \"My Test Podcast\",\n",
    "    \"publisher\": \"Test Publisher\",\n",
    "    \"description\": \"A test podcast\",\n",
    "    \"rss_url\": \"https://test.com/feed\",\n",
    "    \"image_url\": \"https://test.com/image.png\",\n",
    "    \"tags\": [\"test\", \"demo\"]\n",
    "}\n",
    "\n",
    "async def create_new_podcast(db, data):\n",
    "    podcast = await create_podcast(db, data)\n",
    "    await db.commit()\n",
    "    return podcast\n",
    "\n",
    "new_podcast = run_async(run_db_operation(lambda db: create_new_podcast(db, new_podcast_data)))\n",
    "print(f\"Created: {new_podcast.name} (ID: {new_podcast.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload podcasts from csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created podcast: All-In\n",
      "Created podcast: Call Her Daddy\n",
      "Created podcast: Conan O'Brien Needs a Friend\n",
      "Created podcast: The Daily\n",
      "Created podcast: The Ezra Klein Show\n",
      "Created podcast: Fresh Air\n",
      "Created podcast: Hard Fork\n",
      "Created podcast: Huberman Lab\n",
      "Created podcast: The Joe Rogan Experience\n",
      "Created podcast: Lex Fridman Podcast\n",
      "Created podcast: The Megyn Kelly Show\n",
      "Created podcast: The Mel Robbins Podcast\n",
      "Created podcast: New Heights With Jason & Travis Kelce\n",
      "Created podcast: Newsroom Robots\n",
      "Created podcast: Pod Save America\n",
      "Created podcast: Talking Headways\n",
      "Created podcast: This Past Weekend w/ Theo Von\n",
      "Created podcast: The Weekly Show with Jon Stewart\n",
      "Created podcast: WTF with Marc Maron\n",
      "\n",
      "Import completed!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('../../podcasts.csv')\n",
    "\n",
    "# Function to safely evaluate string representation of list\n",
    "def parse_tags(tags_str):\n",
    "    try:\n",
    "        return ast.literal_eval(tags_str) if pd.notna(tags_str) else []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Process each podcast\n",
    "async def import_podcasts(db):\n",
    "    for _, row in df.iterrows():\n",
    "        # Check if podcast already exists\n",
    "        existing = await get_podcast_by_rss_url(db, row['rss_url'])\n",
    "        if existing:\n",
    "            print(f\"Skipping existing podcast: {row['name']}\")\n",
    "            continue\n",
    "            \n",
    "        # Prepare podcast data\n",
    "        podcast_data = {\n",
    "            'name': row['name'],\n",
    "            'publisher': row['publisher'] if pd.notna(row['publisher']) else None,\n",
    "            'description': row['description'],\n",
    "            'rss_url': row['rss_url'],\n",
    "            'image_url': row['image_url'],\n",
    "            'tags': parse_tags(row['tags']),\n",
    "            'frequency': str(row['frequency']) if pd.notna(row['frequency']) else None,\n",
    "            'created_at': datetime.now(pytz.UTC)\n",
    "        }\n",
    "        \n",
    "        # Create the podcast\n",
    "        try:\n",
    "            await create_podcast(db, podcast_data)\n",
    "            print(f\"Created podcast: {podcast_data['name']}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating podcast {podcast_data['name']}: {str(e)}\")\n",
    "    \n",
    "    # Commit all changes\n",
    "    await db.commit()\n",
    "\n",
    "# Run the import\n",
    "result = run_async(run_db_operation(import_podcasts))\n",
    "print(\"\\nImport completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update from podcasts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting update process...\n",
      "Starting podcast updates...\n",
      "Processing All-In...\n",
      "Found change in publisher: None -> All-In Podcast, LLC\n",
      "Updated podcast: All-In\n",
      "Processing Call Her Daddy...\n",
      "Found change in publisher: None -> Alex Cooper\n",
      "Updated podcast: Call Her Daddy\n",
      "Processing Conan O'Brien Needs a Friend...\n",
      "Found change in publisher: None -> Team Coco & Earwolf\n",
      "Updated podcast: Conan O'Brien Needs a Friend\n",
      "Processing The Daily...\n",
      "Found change in publisher: None -> The New York Times\n",
      "Updated podcast: The Daily\n",
      "Processing The Ezra Klein Show...\n",
      "Found change in publisher: None -> New York Times Opinion\n",
      "Updated podcast: The Ezra Klein Show\n",
      "Processing Fresh Air...\n",
      "Found change in publisher: None -> NPR\n",
      "Updated podcast: Fresh Air\n",
      "Processing Hard Fork...\n",
      "Found change in publisher: None -> The New York Times\n",
      "Updated podcast: Hard Fork\n",
      "Processing Huberman Lab...\n",
      "Found change in publisher: None -> Scicomm Media\n",
      "Updated podcast: Huberman Lab\n",
      "Processing The Joe Rogan Experience...\n",
      "Found change in publisher: None -> Joe Rogan\n",
      "Updated podcast: The Joe Rogan Experience\n",
      "Processing Lex Fridman Podcast...\n",
      "Found change in publisher: None -> Lex Fridman\n",
      "Updated podcast: Lex Fridman Podcast\n",
      "Processing The Megyn Kelly Show...\n",
      "Found change in publisher: None -> SiriusXM\n",
      "Updated podcast: The Megyn Kelly Show\n",
      "Processing The Mel Robbins Podcast...\n",
      "Found change in publisher: None -> Mel Robbins\n",
      "Updated podcast: The Mel Robbins Podcast\n",
      "Processing New Heights With Jason & Travis Kelce...\n",
      "Found change in publisher: None -> Wondery\n",
      "Updated podcast: New Heights With Jason & Travis Kelce\n",
      "Processing Newsroom Robots...\n",
      "Found change in publisher: None -> Nikita Roy\n",
      "Updated podcast: Newsroom Robots\n",
      "Processing Pod Save America...\n",
      "Found change in publisher: None -> Crooked Media\n",
      "Updated podcast: Pod Save America\n",
      "Processing Talking Headways...\n",
      "Found change in publisher: None -> The Overhead Wire\n",
      "Updated podcast: Talking Headways\n",
      "Processing This Past Weekend w/ Theo Von...\n",
      "Found change in publisher: None -> Theo Von\n",
      "Updated podcast: This Past Weekend w/ Theo Von\n",
      "Processing The Weekly Show with Jon Stewart...\n",
      "Found change in publisher: None -> Comedy Central\n",
      "Updated podcast: The Weekly Show with Jon Stewart\n",
      "Processing WTF with Marc Maron...\n",
      "Found change in publisher: None -> Marc Maron\n",
      "Updated podcast: WTF with Marc Maron\n",
      "Committing changes...\n",
      "\n",
      "Update completed! Modified 19 podcasts.\n",
      "Update process finished!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "import asyncio\n",
    "\n",
    "# Read the CSV file\n",
    "df = pd.read_csv('../../podcasts.csv')\n",
    "\n",
    "# Function to safely evaluate string representation of list\n",
    "def parse_tags(tags_str):\n",
    "    try:\n",
    "        return ast.literal_eval(tags_str) if pd.notna(tags_str) else []\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Process each podcast\n",
    "async def update_podcasts(db):\n",
    "    updated_count = 0\n",
    "    print(\"Starting podcast updates...\")\n",
    "    \n",
    "    for _, row in df.iterrows():\n",
    "        print(f\"Processing {row['name']}...\")\n",
    "        # Check if podcast exists\n",
    "        existing = await get_podcast_by_rss_url(db, row['rss_url'])\n",
    "        if not existing:\n",
    "            print(f\"Skipping non-existent podcast: {row['name']}\")\n",
    "            continue\n",
    "            \n",
    "        # Prepare podcast data\n",
    "        podcast_data = {\n",
    "            'name': row['name'],\n",
    "            'publisher': row['publisher'] if pd.notna(row['publisher']) else None,\n",
    "            'description': row['description'],\n",
    "            'image_url': row['image_url'],\n",
    "            'tags': parse_tags(row['tags']),\n",
    "            'frequency': str(row['frequency']) if pd.notna(row['frequency']) else None,  # Convert to string\n",
    "        }\n",
    "        \n",
    "        # Check if any data has changed\n",
    "        has_changes = False\n",
    "        for key, value in podcast_data.items():\n",
    "            current_value = getattr(existing, key)\n",
    "            if current_value != value:\n",
    "                print(f\"Found change in {key}: {current_value} -> {value}\")\n",
    "                has_changes = True\n",
    "                setattr(existing, key, value)\n",
    "        \n",
    "        if has_changes:\n",
    "            existing.updated_at = datetime.now(pytz.UTC)\n",
    "            updated_count += 1\n",
    "            print(f\"Updated podcast: {podcast_data['name']}\")\n",
    "    \n",
    "    # Commit all changes\n",
    "    print(\"Committing changes...\")\n",
    "    await db.commit()\n",
    "    print(f\"\\nUpdate completed! Modified {updated_count} podcasts.\")\n",
    "    return updated_count\n",
    "\n",
    "# Run the update with explicit event loop handling\n",
    "try:\n",
    "    loop = asyncio.get_running_loop()\n",
    "except RuntimeError:\n",
    "    loop = asyncio.new_event_loop()\n",
    "    asyncio.set_event_loop(loop)\n",
    "\n",
    "print(\"Starting update process...\")\n",
    "result = loop.run_until_complete(run_db_operation(update_podcasts))\n",
    "print(\"Update process finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Episode Operations\n",
    "\n",
    "### Get Recent Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recent = run_async(run_db_operation(lambda db: get_recent_episodes(db, limit=5)))\n",
    "\n",
    "for ep in recent:\n",
    "    print(f\"\\nEpisode: {ep.title}\")\n",
    "    print(f\"Podcast: {ep.podcast.name}\")\n",
    "    print(f\"Published: {ep.publish_date}\")\n",
    "    if ep.summary:\n",
    "        print(f\"Summary: {ep.summary[:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Episodes for a Specific Podcast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your podcast ID\n",
    "PODCAST_ID = \"your-podcast-id-here\"\n",
    "\n",
    "episodes = run_async(run_db_operation(lambda db: get_podcast_episodes(db, PODCAST_ID)))\n",
    "\n",
    "for ep in episodes:\n",
    "    print(f\"\\nEpisode: {ep.title}\")\n",
    "    print(f\"Published: {ep.publish_date}\")\n",
    "    print(f\"GUID: {ep.rss_guid}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create New Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_episode_data = {\n",
    "    \"podcast_id\": \"your-podcast-id-here\",  # Replace with actual ID\n",
    "    \"rss_guid\": \"unique-guid-here\",\n",
    "    \"title\": \"Test Episode\",\n",
    "    \"publish_date\": datetime.now(timezone.utc),\n",
    "    \"summary\": \"A test episode\"\n",
    "}\n",
    "\n",
    "async def create_new_episode(db, data):\n",
    "    episode = await create_episode(db, data)\n",
    "    await db.commit()\n",
    "    return episode\n",
    "\n",
    "new_episode = run_async(run_db_operation(lambda db: create_new_episode(db, new_episode_data)))\n",
    "print(f\"Created: {new_episode.title} (ID: {new_episode.id})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find Episode by GUID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your episode GUID\n",
    "EPISODE_GUID = \"your-guid-here\"\n",
    "\n",
    "episode = run_async(run_db_operation(lambda db: get_episode_by_guid(db, EPISODE_GUID)))\n",
    "if episode:\n",
    "    print(f\"Found: {episode.title}\")\n",
    "    print(f\"Podcast ID: {episode.podcast_id}\")\n",
    "    print(f\"Published: {episode.publish_date}\")\n",
    "else:\n",
    "    print(\"Episode not found\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lettercast--HXX48EP-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
